{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MarketPlace HPC Gateway SDK\n",
    "\n",
    "The HPC gateway SDK is provide for the app developers or the MarketPlace user to run the time consuming tasks over the clusters.\n",
    "You can install this python SDK and use it to interact with the cluster to run the simulation jobs.\n",
    "We have two HPC deployments in the MarketPlace, the EPFL Materials Cloud (mc) and the IWM deployment.\n",
    "\n",
    "- The `iwm` deployment **does not** have the slurm running properly on the cluster at the moment, therefore the job submit is not working, but all other capabilities are working.\n",
    "- The EPFL Materials Cloud (mc) deployment support all capabilities and app developers can use it embeded in the app that need to running the heavy calculations. \n",
    "However, the `mc` deployment is only for test, the time limit of the job is hard code to 10 minutes. \n",
    "The `mc` deployment will not be maintained after March 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the SDK\n",
    "\n",
    "The HPC gateway SDK is provide for the app developers or the MarketPlace user to run the time consuming tasks over the clusters.\n",
    "To install the SDK package run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install marketplace-hpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the app instance\n",
    "\n",
    "Use `hpc_gateway_sdk.get_app` to create an interface to intereact with the HPC gateway app.\n",
    "The name can be either `iwm` or `mc` for two deployment. \n",
    "\n",
    "Note the `iwm` deployment **don't** have the slurm running properly at the moment, therefore the job submit is not working, but all other capabilities are working.\n",
    "\n",
    "The EPFL Materials Cloud (mc) deployment support all capabilities and app developers can use it embeded in the app that need to running the heavy calculations. \n",
    "However, the `mc` deployment is only for test, the time limit of the job is hard code to 10 minutes. \n",
    "The `mc` deployment will not be maintained after March 2023.\n",
    "To initialize the instance, provide the deployment name and MarketPlace `access_token`. \n",
    "The access_token can be relay from the App that using the hpc gateway app as calculation backend.\n",
    "To run this notebook, put the `.env` file with `ACCESS_TOKEN` set in the same folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpc_gateway_sdk import get_app\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "access_token = os.environ.get(\"ACCESS_TOKEN\")\n",
    "app = get_app(name=\"mc\", access_token=access_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first time using the HPC gateway app, you need to create the user in the database of HPC app to record the job data conrespond to every MarketPlace user account.\n",
    "Meanwhile, `create_user` will create the user folder in the cluster to store jobs folder repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"_id\": \"638f355e57bd4aa2a97b98d0\", \n",
      "  \"email\": \"jusong.yu@epfl.ch\", \n",
      "  \"home\": \"/scratch/snx3000/jyu/firecrest/jusong_yu\", \n",
      "  \"message\": \"Success: Create user in database.\", \n",
      "  \"name\": \"Jusong Yu\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_info = app.create_user()\n",
    "print(user_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a job, using `create_job` endpoint of the gateway app.\n",
    "It will create a job folder in the remote cluster to store files and to submit job.\n",
    "The `jobid` is returned for further operations.\n",
    "The parameter `new_transformation` is a dict for the job information and is used to create the slurm job script.\n",
    "The following parameters must be provide to create the job.\n",
    "\n",
    "- `job_name`: the name of the job.\n",
    "- `ntasks_per_node`: the numper of tasks per node a.k.a the mpi stacks of your job, is the number follow the `mpirun -n`.\n",
    "- `partition`: for the EPFL Materials Cloud (mc) deployment, the partition can be used are `debug` and `normal`. \n",
    "- `image`: For security and agile deployment purpose, we use singularity to run the simulation inside the container. The image can be a container from a given URI. Supported URIs include:\n",
    "\n",
    "    - library: Pull an image from the currently configured librar (library://user/collection/container[:tag])\n",
    "    - docker: Pull a Docker/OCI image from Docker Hub, or another OCI registry.(docker://user/image:tag)\n",
    "    - shub: Pull an image from Singularity Hub (shub://user/image:tag)\n",
    "    - oras: Pull a SIF image from an OCI registry that supports ORAS. (oras://registry/namespace/image:tag)\n",
    "    - http, https: Pull an image using the http(s?) protocol\n",
    "- executable_cmd: the command to run the simulation inside the container.\n",
    "\n",
    "We not yet support using private docker register of MarketPlace (distributed on gitlab). \n",
    "Once we have a gitlab account for this purpose, just set following environment variables on the remote cluster.\n",
    "\n",
    "```bash\n",
    "export SINGULARITY_DOCKER_USERNAME='$oauthtoken'\n",
    "export SINGULARITY_DOCKER_PASSWORD=<redacted>\n",
    "```\n",
    "\n",
    "As mentioned, the EPFL Materials Cloud (mc) deployment is only for test purpose, the time is limited to 10 mins.\n",
    "\n",
    "To build a container that can run the parallel simulation, please check the example of the LAMMPS and Quantum ESPRESSO dockerfile on https://github.com/containers4hpc.\n",
    "The container is encouraged to build based on the `base-mpi314` image which use MPICH v3.1.4 that supoort [ABI compatible](https://www.mpich.org/abi/) and can run with multiple compatible MPI library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "639615ac5be67d529e2187cd\n"
     ]
    }
   ],
   "source": [
    "jobid = app.create_job(new_transformation={\n",
    "  \"job_name\": \"demo00\",\n",
    "  \"ntasks_per_node\": 1,\n",
    "  \"partition\": \"debug\",\n",
    "  \"image\": \"docker://hello-world:latest\",\n",
    "  \"executable_cmd\": \"> output\",\n",
    "})\n",
    "print(jobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `create_job` only will prepare the folder and the slurm job script in the remote cluster, to launch the simulation we provide the `launch_job`.\n",
    "Pass the jobid from the output of `create_job`, the job will be launched in the remote cluster. \n",
    "The email of job state will be send to user by the email registered, of the MarketPlace account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jobid': '639615ac5be67d529e2187cd'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = app.launch_job(jobid)\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `check_job_state` is used to getting the file list of the job. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'files': [{'group': 'mrcloud',\n",
       "   'last_modified': '2022-12-11T18:38:52',\n",
       "   'link_target': '',\n",
       "   'name': 'job.sh',\n",
       "   'permissions': 'rw-r--r--',\n",
       "   'size': '519',\n",
       "   'type': '-',\n",
       "   'user': 'jyu'},\n",
       "  {'group': 'mrcloud',\n",
       "   'last_modified': '2022-12-11T18:39:01',\n",
       "   'link_target': '',\n",
       "   'name': 'slurm-43437415.out',\n",
       "   'permissions': 'rw-r--r--',\n",
       "   'size': '0',\n",
       "   'type': '-',\n",
       "   'user': 'jyu'}],\n",
       " 'message': 'Files in the job folder.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = app.check_job_state(jobid)\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can cancel the job by `cancel_job`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Send cancelling signal to job-639615ac5be67d529e2187cd, of f7t job id=43437415'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = app.cancel_job(jobid)\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input files are usually needed to run the simulation, the files can be upload by `upload_file` as the example shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'files': [{'group': 'mrcloud',\n",
       "   'last_modified': '2022-12-11T18:39:07',\n",
       "   'link_target': '',\n",
       "   'name': 'file_upload_test.txt',\n",
       "   'permissions': 'rw-r--r--',\n",
       "   'size': '7',\n",
       "   'type': '-',\n",
       "   'user': 'jyu'},\n",
       "  {'group': 'mrcloud',\n",
       "   'last_modified': '2022-12-11T18:38:52',\n",
       "   'link_target': '',\n",
       "   'name': 'job.sh',\n",
       "   'permissions': 'rw-r--r--',\n",
       "   'size': '519',\n",
       "   'type': '-',\n",
       "   'user': 'jyu'},\n",
       "  {'group': 'mrcloud',\n",
       "   'last_modified': '2022-12-11T18:39:05',\n",
       "   'link_target': '',\n",
       "   'name': 'output',\n",
       "   'permissions': 'rw-r--r--',\n",
       "   'size': '807',\n",
       "   'type': '-',\n",
       "   'user': 'jyu'},\n",
       "  {'group': 'mrcloud',\n",
       "   'last_modified': '2022-12-11T18:39:08',\n",
       "   'link_target': '',\n",
       "   'name': 'slurm-43437415.out',\n",
       "   'permissions': 'rw-r--r--',\n",
       "   'size': '1489',\n",
       "   'type': '-',\n",
       "   'user': 'jyu'}],\n",
       " 'message': 'Files in the job folder.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.upload_file(jobid, filename=\"file_upload_test.txt\", source_path=\"./file_upload_test.txt\")\n",
    "resp = app.check_job_state(jobid)\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the simulation finished or excepted, the output or the slurm error file should be download to check the job details. \n",
    "The binary file is supported, to write it to a file, you can use the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = app.download_file(jobid, filename=\"output\")\n",
    "with open(\"output\", 'wb') as csr:\n",
    "      for chunk in resp.iter_content(chunk_size=1024):\n",
    "          if chunk:\n",
    "              csr.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To delete the file in job folder, use `delete_file`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'files': [{'group': 'mrcloud',\n",
       "   'last_modified': '2022-12-11T18:38:52',\n",
       "   'link_target': '',\n",
       "   'name': 'job.sh',\n",
       "   'permissions': 'rw-r--r--',\n",
       "   'size': '519',\n",
       "   'type': '-',\n",
       "   'user': 'jyu'},\n",
       "  {'group': 'mrcloud',\n",
       "   'last_modified': '2022-12-11T18:39:05',\n",
       "   'link_target': '',\n",
       "   'name': 'output',\n",
       "   'permissions': 'rw-r--r--',\n",
       "   'size': '807',\n",
       "   'type': '-',\n",
       "   'user': 'jyu'},\n",
       "  {'group': 'mrcloud',\n",
       "   'last_modified': '2022-12-11T18:39:08',\n",
       "   'link_target': '',\n",
       "   'name': 'slurm-43437415.out',\n",
       "   'permissions': 'rw-r--r--',\n",
       "   'size': '1489',\n",
       "   'type': '-',\n",
       "   'user': 'jyu'}],\n",
       " 'message': 'Files in the job folder.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.delete_file(jobid, filename=\"file_upload_test.txt\")\n",
    "resp = app.check_job_state(jobid)\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('hpc-app')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff44bf46afe16611456f7c915984caf83c9aa021617754637634791ae1e9af16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
